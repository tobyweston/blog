<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: performance | bad.robot]]></title>
  <link href="http://www.baddotrobot.com/blog/categories/performance/atom.xml" rel="self"/>
  <link href="http://www.baddotrobot.com/"/>
  <updated>2012-02-07T21:12:07+00:00</updated>
  <id>http://www.baddotrobot.com/</id>
  <author>
    <name><![CDATA[Toby Weston]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Performance Monitoring (Part 1)]]></title>
    <link href="http://www.baddotrobot.com/blog/2009/10/31/performance-monitoring-part-1/"/>
    <updated>2009-10-31T00:00:00+00:00</updated>
    <id>http://www.baddotrobot.com/blog/2009/10/31/performance-monitoring-part-1</id>
    <content type="html"><![CDATA[<p>Keeping an eye on the performance of your applications is something that it easy to neglect. We all know that we should be regularly recording key performance indicators and regularly leaning on the profiler to spot dangers early, but how often is the dust actually blown off?</p>

<p>I've been doing a fair bit of this lately (blowing off that is) and thought it
might be a good idea to capture a few thoughts in a mini-series of posts that
will be rivaled in drama only by the likes of Dynasty and Dallas. Enjoy...</p>

<!-- more -->


<h3>Part 1. The Beginning</h3>

<p>It's probably a shrewd move whatever your application to setup performance
measurement early. I'm usually interested in two areas, the real-time
performance and the resource usage.</p>

<h3>Performance</h3>

<p>What you define as "performance" is completely down to you and your
application. It may be in the request / response world, the time taken to
process a request and return a response. It may reflect the ability to handle
thousands of requests within a SLA agreed time or it may be around reliability
and up time, scalability or accuracy. Whatever. Some things that are usually
constant though are an emphasis on time, correctness and robustness of system
under load. This is all about measurement and optimisation.</p>

<ul>
<li><p><strong>Response times</strong> - of your critical path</p></li>
<li><p><strong>Throughput</strong> - typically the number of requests / transactions / operations per second</p></li>
<li><p><strong>Load</strong> - the number of request / transactions / operations being observed.</p></li>
<li><p><strong>Success / failure counts</strong> - it's no good being quick if you're always wrong!</p></li>
<li><p><strong>Garbage collection profile</strong> - you'll probably be more interested in this if your system is already highly performant. In these cases you can potentially see dramatic differences in critical path processing times when excessive or inefficient GC is taking place. Tuning is a specialist skill, good luck. Google Sun's G1 for renewed hope.</p></li>
</ul>


<h3>Resources</h3>

<p>The section on resources is more open ended, I mean hear both hardware
resources and software resources (including the resources available to the
JVM). Of course, taking into account the resource usage of interrelated
external systems may also be of interest to the happy tuner and its all about
avoiding resources starvation and spotting bottlenecks.</p>

<ul>
<li><p><strong>CPU</strong></p></li>
<li><p><strong>Memory</strong> - The JVM can theoretically allocate only 2GB to the heap on 32 bit machines and 16GB on 64 bit machines. In practice, hitting this upper bound with -Xmx can be tricky. Either way, you'll want to understand the memory characteristics of your application and how it behaves if you start to reach the upper bound of the heap.</p></li>
<li><p><strong>IO</strong> - I mean here things like handles, database connections, physical network connections and other tasty bites. Without these, all is lost and managing these to avoid resource starvation can be of primary importance.</p></li>
<li><p><strong>Threads</strong> - there is a relationship between the number of threads your software requires and hardware resources available to you, threads are not unbounded in your application so the prudent coder will seek insight into the affect creating lots of threads will have. See a previous <a href="http://pequenoperro.blogspot.com/2009/02/less-is-more.html">post</a>.</p></li>
</ul>


<h3>Statistic Gathering</h3>

<p>Once we have an idea of what we want to measure, the next step is to think
about how to capture and represent the raw data. We need to capture the raw
data and turn it into information that's useful. It turns out that turning
this data into information will influence how we capture it...</p>

<p>You could capture all the data about every single request but it's unlikely
that this is the information you'll need without doing some form of
manipulation. Instead, I prefer to capture information, manipulating and
aggregating the data from each request as we go.</p>

<p>For example, typically you might be interested in the means, samples or
percentile based information.</p>

<p><a href="http://en.wikipedia.org/wiki/Arithmetic_mean">Mean</a> values are probably the
simplest to get started with, recording figures like mean response time are
useful but not always the full picture. Average figures can be skewed by
extreme results or extreme results may be lost in the mean. Supplementing with
unmodified <a href="http://en.wikipedia.org/wiki/Sample_%28statistics%29">samples</a> can
help give a fuller picture.</p>

<p><a href="http://en.wikipedia.org/wiki/Percentile_rank">Percentile</a> based reporting
gives more insight than a smoothed average figure. For example, if most of the
requests are sub-second, it can be hard to spot the small number of slow
requests. By reviewing at a particular percentile you can gain visibility of
these and help determine what's an acceptable level. For example, the mean
response time at the 95th percentile will likely be noticeably different than
the mean.</p>

<p>Another option is to implement a sliding view on the data. Here, you record
information for, say, an hour and as time progresses beyond that hour, you
start to loose past data and include new data. At most, an hour of data is
available. This can be useful as rather than cumulative counts, the sliding
window is visually more responsive to changes (in particular, drops). For
example, once charted, a drop in a cumulative chart will show as a slow in
accent of the series where with a sliding window chart, it will show as a
clear drop. A subsequent post in the series will talk in more detail about
this sliding window approach.</p>

<h3>Implementing</h3>

<p>There's plenty of ways you can as statistics to your application.
Instrumenting the code at key points through decoration is a good option.
Using something like AspectJ is another option and both free your code from
any clutter that would otherwise pollute and distract from your classes real
responsibilities. Logging is a good example of instrumentation polluting
things. Typically, the act of logging has nothing to do with the role of the
class doing the logging.</p>

<p>The instrumenting code will likely be modifying objects in memory that collect
and manipulate the raw data. You'll almost certainly want to make sure this
memory object is thread safe and performant, it should be light weight and
non-obtrusive.</p>

<p>What happens to the memory object is up to you, but you'll need to output it
for analysis at some point. I prefer to publish the objects via JMX, that way
you can setup a separate 'collector' to periodically read the values and have
it's wicked way with them. With this approach, its even more important to keep
the object lightweight - the MBean will always be in memory (the MBean server
will see to this) and so if it contains rogue references to big objects,
they'll never get garbage collected. The other tip is to create one of these
such objects per request type, don't create a new one per request for example.</p>

<p>In the next exciting post in the series, I'll talk about interpreting the
results you get. Hope that wasn't too dull.</p>

<p><img src="http://4.bp.blogspot.com/_-uMxV_fCbC4/SVInGoVdYJI/AAAAAAAAC08/I4RV1KzCyPo/s320/gibble_22x22.png"></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Less is More]]></title>
    <link href="http://www.baddotrobot.com/blog/2009/02/26/less-is-more/"/>
    <updated>2009-02-26T00:00:00+00:00</updated>
    <id>http://www.baddotrobot.com/blog/2009/02/26/less-is-more</id>
    <content type="html"><![CDATA[<p><a href="https://twitter.com/#!/tarkaTheRotter">Denton</a> was trying to
convince me the other day that less is more when it comes to maximum heap size in Java. After I finally got the point, I was aghast! Shock, horror... creating threads in Java takes up non-VM managed memory!</p>

<blockquote><p>After running a few tests I confirmed that the lower the max heap size is,
the more threads I could create. I can easily get a OutOfMemoryError when
allocating memory for threads way before any real heap space is used.</p></blockquote>

<p>The helpful message you'll get is.</p>

<pre><code>java.lang.OutOfMemoryError: unable to create new native thread
</code></pre>

<p>I ran a simple loop that would create dozy threads (they sleep a lot) and
watched how many threads could be created before the out of memory error
above. I repeated this after setting the maximum heap size. Check out the
results below, you can see that no real Java heap is used, still I get an out
of memory error and am limited on the number of threads I can create. As a
caveat, these results should in no way taken as representative on any other
environment than my laptop running Java 1.6. Your mileage may vary.</p>

<p><a href="http://4.bp.blogspot.com/_-uMxV_fCbC4/SabxCtNlpUI/AAAAAAAADCM/er62bS1oW9Y/s1600-h/64.PNG"><img src="http://4.bp.blogspot.com/_-uMxV_fCbC4/SabxCtNlpUI/AAAAAAAADCM/er62bS1oW9Y/s400/64.PNG"></a></p>

<p><a href="http://2.bp.blogspot.com/_-uMxV_fCbC4/SabxJsaTCWI/AAAAAAAADCU/WM7e4EBwsSU/s1600-h/512.PNG"><img src="http://2.bp.blogspot.com/_-uMxV_fCbC4/SabxJsaTCWI/AAAAAAAADCU/WM7e4EBwsSU/s400/512.PNG"></a></p>

<p><a href="http://1.bp.blogspot.com/_-uMxV_fCbC4/SabxQc8DBkI/AAAAAAAADCc/-O6ApHci_q4/s1600-h/1512.PNG"><img src="http://1.bp.blogspot.com/_-uMxV_fCbC4/SabxQc8DBkI/AAAAAAAADCc/-O6ApHci_q4/s400/1512.PNG"></a></p>

<p><a href="http://4.bp.blogspot.com/_-uMxV_fCbC4/Sab0EHyHXyI/AAAAAAAADCk/6ur4CTR3svI/s1600-h/results.PNG"><img src="http://4.bp.blogspot.com/_-uMxV_fCbC4/Sab0EHyHXyI/AAAAAAAADCk/6ur4CTR3svI/s400/results.PNG"></a></p>

<p>I'd always considered OS native threads or light weight processes to be
effectively unbounded with the restrictions being on the resources they are
associated with. I don't think this is really the case though as clearly, the
act of creating a thread that does nothing and has no real resources
associated with it (other than any native voodoo) requires OS memory
allocation in my tests.</p>

<p>I thought this was really interesting as it demonstrates how small decisions
can have a big impact on the run-time characteristics of a system. Being able
to tune your application to suit your production requirements is always
tricky. Large memory models and data manipulation can often require large heap
sizes but if in addition, you then want to create large numbers of threads,
you might get into the murky world I've touched on here. Of course, thread
pools are generally the way to go if you want to manage your resources
properly, but that's another story all together.</p>

<p>I'm sure Google can tell you more, but see this <a href="http://www.egilh.com/blog/archive/2006/06/09/2811.aspx">random blog</a> for another
description.</p>

<p><img src="http://4.bp.blogspot.com/_-uMxV_fCbC4/SVInGoVdYJI/AAAAAAAAC08/I4RV1KzCyPo/s320/gibble_22x22.png"></p>
]]></content>
  </entry>
  
</feed>
