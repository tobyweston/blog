<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: agile | bad.robot]]></title>
  <link href="http://baddotrobot.com/blog/categories/agile/atom.xml" rel="self"/>
  <link href="http://baddotrobot.com/"/>
  <updated>2019-10-30T14:28:24+00:00</updated>
  <id>http://baddotrobot.com/</id>
  <author>
    <name><![CDATA[Toby Weston]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Evidencing Source Code Reviews]]></title>
    <link href="http://baddotrobot.com/blog/2019/10/30/evidencing-source-code-reviews/"/>
    <updated>2019-10-30T08:16:00+00:00</updated>
    <id>http://baddotrobot.com/blog/2019/10/30/evidencing-source-code-reviews</id>
    <content type="html"><![CDATA[<p>Many industries need to evidence that code reviews have taken place. This is typical in regulated environments like Banking but the Regulators aren't clear what constitutes a good source code review process and don't yet understand modern practices like Pair Programming. They can't help you streamline your process.</p>

<p>The result is a tension between old-fashioned bureaucracy and modern development practices; the need to prove you have a rigorous process in-place and the desire to push frequent releases to production without wasteful paperwork.</p>

<!-- more -->


<h2>The Regulators</h2>

<p>The Monetary Authority of Singapore (MAS) is Singapore's central bank and regulatory authority. If you want to do business in Singapore, you need to comply with their regulations. They've published what they call the Technology Risk Management (TRM) Guidelines to help with "the adoption of sound practices and processes for managing technology". Each financial institution with an interest in Singapore is expected to adopt these guidelines with the following caveat.</p>

<p><blockquote><p>"Financial institutions (FIs) may adapt these guidelines, taking into account the diverse activities they engage in and the markets in which they conduct transactions. FIs should read the Guidelines in conjunction with relevant regulatory requirements and industry standards."</p><footer><strong>Monetary Authority of Singapore</strong> <cite>TRM Guidelines - Section 2.0.1</cite></footer></blockquote></p>

<p>One area of the TRM guidelines talks about the need to conduct code reviews (section 6.3). Each institution must interpret these guidelines and be comfortable articulating how the manage the source code review process. The TRM guidelines don't say <em>how</em> to conduct reviews and doing effective code reviews is hard.</p>

<p>Regulators struggle to keep up with modern software development practices and how they can help give confidence that guidelines are being followed. They struggle to assess the impact of things like containerised deployments and having data on the public cloud. For source code reviews, each institution must adapt the guidelines to fit their development practices but at a minimum, each should be able to provide evidence.</p>

<h2>Evidence</h2>

<p>So how do we evidence that code reviews have taken place? A traditional process would be to conduct an out-of-band code review (after the coding task has been completed) and document it via some tool like Codacy or Crucible. GitHub (and GitHub Enterprise) have nice integrated review tools and BitBucket have something similar. These are often combined with the act of merging a Pull Request, i.e. you do the code review when you accept a PR.</p>

<h3>Trunk Based Development vs Branch</h3>

<p>Tools that combine merging branches with code reviews <strong>conflate two distinct ideas</strong> (managing your source code and peer reviewing source code). If you do both actions together, your branching model has been chosen for you and doing trunk based development (TBD) becomes harder. If you do try for TBD and use short lived branches purely to facilitate code reviews, <strong>you're introducing waste</strong> (albeit the cost may be reclaimed somewhat by the tooling that motivated the decision).</p>

<p>Trunk based development has lots of advantages in it own right, not least of which is that it offers <strong>continuous integration</strong> (CI). CI has been around since the early 90s and helps reduce the feedback loop for dev teams. Compared to long running feature branches where by definition, integration takes place intermittently and infrequently, it helps find potential problems early.</p>

<p><blockquote><p>"Continuous Integration doesnâ€™t get rid of bugs, but it does make them dramatically easier to find and remove."</p><footer><strong>Martin Fowler</strong> <cite>Chief Scientist @ ThoughtWorks</cite></footer></blockquote></p>

<h3>Pair Programming vs Code Reviews</h3>

<p>Pair Programming as an alternative to traditional out-of-band code reviews offer significant advantages. Again, mostly this is around <strong>shortening the feedback loop</strong> and fixing potential problems early. If code reviews are a good idea, why not do them all the time? When you're actually coding and not when you've finished?</p>

<p>So how do you practice trunk based developed, utilise Pair Programming and still provide evidence that you've had multiple developers work on a single piece of code? Perhaps crypto-evidence can help?</p>

<h2>Crypto-evidence</h2>

<p>Crypto-evidence is a term I made up for this post but it implies that we should be able to supply evidence that can be proven via cryptographical means. With traditional techniques, a code reviewer can be proven to be who she says she is (and that she's a different person than the original author) by the login credentials used with the review and VCS tools. These would be encrypted and so (in theory) can not be subverted or faked. Assuming the rest of the review is locked down, we have our evidence.</p>

<h3>Git Digital Signatures</h3>

<p>Git is probably the most widely used VCS today (some figures suggesting it's used by 70% of projects). It offers a feature called <strong>signed commits</strong> whereby the person committing code digitally signs the commit with GPG. This can be retrieved (along with the author information) and, in theory, prove a different individual "signed" a commit than it's author. This signature could be used as a sign-off for a code review as only the signatory knows her passphrase. Just use <code>-S</code> (not <code>-s</code>):</p>

<pre><code class="bash">$ git -S -m "initial commit"
</code></pre>

<p>...and verify with <code>git log --show-signature</code>:</p>

<pre><code class="bash">$ git log --show-signature
commit d001cb9e78a2dbf4ce8ddad3eb2fe8b14234e3c5 (HEAD -&gt; master)
gpg: Signature made Wed 30 Oct 12:37:18 2019 GMT
gpg:                using RSA key 39E273602
gpg: Good signature from "Toby (baddotrobot.com) &lt;toby@badrobot.com&gt;" [ultimate]
Author: Toby &lt;toby@badrobot.com&gt;
Date:   Wed Oct 30 12:37:18 2019 +0000

    initial commit
</code></pre>

<p>The key line includes <code>Signature made ... using RSA key 39E273602</code>. Job done? Not quite...</p>

<h3>Proving Pair Programming</h3>

<p>I brushed over a little bit there. Assuming we want to prove Pair Programming was being done, we need to show an alternative author from the signatory. We can do that either supplying the <code>--author</code> argument or (more practically) sharing the team's private keys securely and signing based on who's at the computer.</p>

<ol>
<li><p>On my computer (the default key is set with <code>git config --global user.signingkey 39E273602</code>) and with Barry pairing:</p>

<pre><code class="bash">$ git commit -S --author="Barry &lt;barry@badrobot.com&gt;" -m "commit from Toby's machine with Barry as the author"
</code></pre></li>
<li><p>Or, if each machine has every developer's private key installed in GPG, we can rotate developers and sign from every machine.</p>

<p>From Barry's machine (with Toby pairing):</p>

<pre><code class="bash">$ git commit -Stoby -m "commit as Barry with Toby signing the commit"
</code></pre></li>
</ol>


<p>Both would result in something like the following.</p>

<pre><code class="bash">$ git log --show-signature
commit e128af7f51e272eae29cee8f1c124ec0be3b64ad (HEAD -&gt; master)
gpg: Signature made Wed 30 Oct 12:54:49 2019 GMT
gpg:                using RSA key 39E273602
gpg: Good signature from "Toby (baddotrobot.com) &lt;toby@badrobot.com&gt;" [ultimate]
Author: Barry &lt;barry@badrobot.com&gt;
Date:   Wed Oct 30 12:54:49 2019 +0000

    commit as Barry with Toby signing the commit
</code></pre>

<p>Showing Toby as the signatory (code reviewer) and Barry as the the author. Cryptographically provable that two developers worked on the code.</p>

<p>When you force each commit to be signed (with <code>git config --global commit.gpgsign true</code>), you should be able to build a report from the Git log showing every commit was paired on.</p>

<pre><code class="bash">$ git lgs
* e128af7 - (HEAD -&gt; master) commit showing alt author (21 minutes ago) &lt;Barry&gt; (ðŸ”’ Toby &lt;toby@badrobot.com.com&gt;)
* fa6f6e5 - commit showing alt author (34 minutes ago) &lt;Barry&gt; (ðŸ”’ Toby &lt;toby@badrobot.com.com&gt;)
* d001cb9 - initial commit (38 minutes ago) &lt;Toby&gt; (ðŸ”’ Barry &lt;barry@badrobot.com.com&gt;)
</code></pre>

<h3>Sharing and Importing Secrets</h3>

<p>To share private keys, export your key (you may choose to share this via Git alongside your source code).</p>

<pre><code class="bash">$ gpg --export-secret-key --armor toby@badrobot.com &gt; secretkey_toby.asc
</code></pre>

<p>...and import it on each developer's machine.</p>

<pre><code class="bash">gpg --import secretkey_toby.asc
</code></pre>

<p>Just pass in the name you used when creating the key to the <code>-S</code> argument. In my case <code>-Stoby</code>.</p>

<h1>Why it Doesn't Work</h1>

<p>Unfortunately, this technique doesn't come without it's problems.</p>

<ul>
<li>Rebasing will overwrite the signatories</li>
<li>Tool support means the terminal is the only option</li>
<li>Sharing private keys</li>
</ul>


<p>Rebasing will rewrite a commit after pulling down changes. As it attempt to rewrite the commit, it will take your <code>commit.gpgsign</code> setting into account and potentially overwrite someone else signature with your own. If the setting is <code>false</code>, it will appear as if there was no signatory. This is potentially a deal breaker as rebasing (from a single branch as is the case for TBD) is a <strong>very</strong> common use case. Even if merging is used within a team, it only takes one rebase to subvert the entire process.</p>

<p>IDE support is limited. IntelliJ IDEA doesn't support it (vote for the <a href="https://youtrack.jetbrains.com/issue/IDEA-110261">issue here</a>) so you're left to use the command line for commits. Your VCS system might also cause your problems - your organisation might reject commits where the <code>--author</code> has changed.</p>

<h2>Summary</h2>

<p>Git's signed commit feature was never meant for this. It's really a way to prove a commit came from who it was claimed to come from. It was motivated by large open source projects where the authenticity of commits is required (for example, for merging only from trusted authors). We're trying to misuse the feature here and we get someway in achieving our goals with it, it just breaks down in a few key areas.</p>

<p>A warning from Git's own documentation:</p>

<p><blockquote><p>Signing tags and commits is great, but if you decide to use this in your normal workflow, youâ€™ll have to make sure that everyone on your team understands how to do so. If you donâ€™t, youâ€™ll end up spending a lot of time helping people figure out how to rewrite their commits with signed versions. Make sure you understand GPG and the benefits of signing things before adopting this as part of your standard workflow.</p><footer><strong>Git - Signing Your Work</strong> <cite><a href='https://git-scm.com/book/en/v2/Git-Tools-Signing-Your-Work'>Git Tools</a></cite></footer></blockquote></p>

<h2>References</h2>

<ul>
<li><a href="https://git-scm.com/book/en/v2/Git-Tools-Signing-Your-Work">Git - Signing your Work</a></li>
<li><a href="https://softwareengineering.stackexchange.com/questions/136079/are-there-any-statistics-that-show-the-popularity-of-git-versus-svn">Git adoption figures</a></li>
<li><a href="https://www.toptal.com/software/trunk-based-development-git-flow">TBD vs Branching</a></li>
<li><a href="https://www.mas.gov.sg/-/media/MAS/Regulations-and-Financial-Stability/Regulatory-and-Supervisory-Framework/Risk-Management/TRM-Guidelines--21-June-2013.pdf">Technology Risk Management Guidelines</a></li>
</ul>


<h2>Miscellaneous Setup</h2>

<h3>Reporting</h3>

<p>With the following alias, you can print a nice one liner per commit including who signed it.</p>

<pre><code class="bash">$ git config --global alias.lgs "log --graph --pretty=format:'%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)&lt;%an&gt;%Creset %C(yellow)(ðŸ”’ %GS)%Creset' --abbrev-commit --date=relative"
</code></pre>

<pre><code class="bash">$ git lgs
* e128af7 - (HEAD -&gt; master) commit showing alt author (21 minutes ago) &lt;Barry&gt; (ðŸ”’ Toby &lt;toby@badrobot.com.com&gt;)
* fa6f6e5 - commit showing alt author (34 minutes ago) &lt;Barry&gt; (ðŸ”’ Toby &lt;toby@badrobot.com.com&gt;)
* d001cb9 - initial commit (38 minutes ago) &lt;Toby&gt; (ðŸ”’ Barry &lt;barry@badrobot.com.com&gt;)
</code></pre>

<h3>Troubleshooting</h3>

<p>To test your GPG program, run the following.</p>

<pre><code class="bash">$ echo "test" | gpg --clearsign
</code></pre>

<p>If the output includes the following.</p>

<pre><code class="bash">gpg: signing failed: Inappropriate ioctl for device
gpg: [stdin]: clear-sign failed: Inappropriate ioctl for device
</code></pre>

<p>You may need to run the following (I did on MacOSX).</p>

<pre><code class="bash">$ export GPG_TTY=$(tty)
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Refactoring in 10 Minutes]]></title>
    <link href="http://baddotrobot.com/blog/2019/08/09/refactoring-in-10-minutes/"/>
    <updated>2019-08-09T11:40:00+01:00</updated>
    <id>http://baddotrobot.com/blog/2019/08/09/refactoring-in-10-minutes</id>
    <content type="html"><![CDATA[<p>I recently created a free place online to collect training materials and videos around eXtreme Programming. I'm creating or curating a set of live workshops, check it out at <a href="https://xpdojo.org">https://xpdojo.org</a>.</p>

<p>The first video on the site gives an introduction to refactoring and some examples in Java from chapter 1 of <a href="https://amzn.to/31rSy4U">Martin Fowler's book</a>. The source code is on <a href="https://github.com/tobyweston/Refactoring-Chapter-1">GitHub</a>.</p>

<p><div class="embed-video-container"><iframe src="http://www.youtube.com/embed/-lkiccO8h6w "></iframe></div></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Daily Standups Don't Work]]></title>
    <link href="http://baddotrobot.com/blog/2012/09/15/daily-standups-dont-work/"/>
    <updated>2012-09-15T06:12:00+01:00</updated>
    <id>http://baddotrobot.com/blog/2012/09/15/daily-standups-dont-work</id>
    <content type="html"><![CDATA[<p>At some point, standups have stopped working for me. They've certainly moved away from the original intention to improve collaboration and communication. I'm not sure I can put my finger on why, but I'm just not getting much out of them any more. It's led me to think that standups per se just don't work. At least in most of the environments I've encountered. So I've been thinking about what could work in their place and I think its just to <em>talk</em> more.</p>

<!-- more -->


<h2>Typical Problems</h2>

<p>Some typical problems I see again and again include standups taking too long; standups becoming a tool to chase progress or apply pressure and attendees glazing over when it's not their turn to speak. <a href="http://jchyip.blogspot.co.uk/">Jason Yip</a> talks about some other <a href="http://martinfowler.com/articles/itsNotJustStandingUp.html#HowDoWeKnowWhenAStand-upIsGoingPoorly">common problems</a>. The biggest problem that I see though, is that standups have become more about the "status update" than communication and collaboration.</p>

<h2>It's Not A Status Update</h2>

<p>If your standup is more about the status update than anything else, the rot may have already set in. It's a shame  the first sentence of the <a href="https://en.wikipedia.org/wiki/Stand-up_meeting">wikipedia page</a> defines a standup as being a "status update". In fact, nearly every page on the subject talks about it in terms of a "status update". Nonsense.</p>

<p>In my view, it should be about communication and collaboration. The trouble with "status update" as a phrase, is that it has dark undertones. It has <em>reporting</em> connotations and can promote a command and control relationship. It's pretty common for team leads, project managers or other stakeholders to coerce the standup into a tool for reporting. <strong>That's what the board is for.</strong></p>

<p>When it becomes a tool to apply pressure or push a project management agenda, things can get pretty negative. Good team leads, managers and stakeholders will use the board for status updates and go round the team individually as they need to. It's all too easy to condense this into an intense experience at standup but it won't tell them the whole story. Those in project management roles have to work hard to preserve the spirit of the standup and get management information in other ways.</p>

<h2>Communication &amp; Collaboration</h2>

<p>If the spirit of the standup is really about communication and collaboration, why don't we apply the same principles we apply with Extreme Programming, namely, to apply it all the time? <strong>I'd prefer standups to be more organic.</strong> Why not jump up and start a conversation when you feel like it? Grab anyone who looks up. Why prescribe a meeting first thing, when you may not have anything to talk about? When you're working in the same physical proximity, it's natural to overhear and contribute to the conversations around you. Standup, get involved.</p>

<p>The standard <a href="http://www.extremeprogramming.org/rules/standupmeeting.html">three report items</a> feel a bit arbitrary and anyway, they're really intended as a guide, not a mantra. I'd go further than that and suggest that even the idea of <em>reporting</em> at standup is the thin end of the wedge. The three questions promote the idea of <em>reporting</em> when we should be promoting the idea of <em>collaboration</em>.</p>

<p>In the same way, wouldn't it be nice if you pair with whomever, whenever the time is right? Rather than move board avatars around in the morning at standup to organising pairs, wouldn't it be nice to seek a collaborator as you need to and change them often? A bit like socks.</p>

<h2>The Good Bits</h2>

<p>Of course, none of this may be ringing true for you. Standups might be the perfect forum for communication for your team. Despite the title, I don't mean to suggest it plainly never works. I just want to emphasise how difficult it is to get it to work and avoid the pitfalls. There may even be a simpler, less leading mechanisms to promote communication and keep team focus. I'm talking here about <em>natural</em> conversation and social cohesion.</p>

<p>To offer at least a token effort at balance; even in a dysfunctional standup, I can still find a few things useful. I do like to start the day with a focusing session. A bit like <a href="/blog/2012/07/20/getting-things-done-i">GTD</a> where you ask "what is my immediate next action?". It can also be a convenient time to pair up for the day and unfortunately, it does work as a status update tool for management.</p>

<h2>That's All Folks</h2>

<p>It's down to individuals in the team to engage. Forcing a standup meeting isn't going to do that. Individuals should be nosey, keeping an eye on the board and the backlog. They don't need to stand in front of the board and watch cards go up or move to the right in a daily standup to do that. They don't need to listen to a synopsis of yesterday's work if they were listening to it unfold yesterday. Management need another forum if they're hijacking your standup and as an engaged individual, it's up to you to champion that change.</p>

<p>Like a lot of the agile practices, its easy to fall into the habit of the daily standup without stopping to consider why we're doing so. If you really don't think you're getting much out of it, stop and question things. Following agile practices mechanically isn't the goal in itself; it's about more than that.</p>

<p>If you fancy shaking things up, <a href="http://www.planningforfailure.com/">Todd Charron</a>'s created an interactive course with practical ideas to improve your standup. <a href="http://www.udemy.com/improv-your-agile-scrum-stand-up?couponCode=pffcommented">Check it out</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Pair Tests: What Candidates Can Expect]]></title>
    <link href="http://baddotrobot.com/blog/2012/07/04/pair-tests-what-candidates-can-expect/"/>
    <updated>2012-07-04T18:58:00+01:00</updated>
    <id>http://baddotrobot.com/blog/2012/07/04/pair-tests-what-candidates-can-expect</id>
    <content type="html"><![CDATA[<p><img itemprop="image" class="right" src="../../../../../images/pairing.jpg"></p>

<p>If you haven't had the opportunity to pair much in your day job, it may seem a little unfair to be <em>tested</em> on the subject. More and more, people are trying to recreate working environments in order to assess candidates and that means <em>pairing</em>. The trouble is, <em>pair tests</em> are often not an accurate recreation and it takes some skill from both candidate and interviewer to get through a pair test smoothly.</p>

<p>This post talks a little about what to expect from a pair test and offers a few tips to surviving the process.</p>

<!-- more -->


<h2>What To Expect</h2>

<p>Typically, you'll sit down with one or two developers, be introduced to a basic problem and asked to solve it. If it's a good sample problem, you can expect to be asked to implement or fix small, incremental pieces of functionality. It's unfortunate that we use the term "pair test". I don't see it as a "test" but as an exercise or discussion. There shouldn't be a single right or wrong answer. The prospective employer should really be looking at <em>how you work</em> rather than <em>did she solve the problem?</em> A good <em>coding exercise</em> is simple and open ended.</p>

<p>Expect to be put at ease. The interviewer should make every effort to relax you and communicate their expectations. If you find that your dropped in the deep end and bombarded with all kinds of devious scenarios, you have to question the organisation's values.</p>

<p>Expect a choice of IDE. If you're not given a choice, don't expect to be judged on your knowledge of the IDE.</p>

<p>Expect to be coding for an hour to two. They inevitably take a while and it's unrealistic to expect a productive pairing session in just thirty minutes.</p>

<p>After the exercise, you may be asked "how did you find that?". If not, I like to ask the interviewer "how was that? Was it the kind of thing you were looking for?". It may lead to further conversations that give you the chance to talk about things in more depth, discuss alternatives and generally impress.</p>

<h2>Be Yourself</h2>

<p>There's often an unspoken expectation that you'll be demonstrating your mad TDD skills. I think deep down though, people are interested in seeing how you work, not necessarily that you work in a test driven way. I think it's fair to say people do expect to see some tests, so make sure you write <em>some</em>. My point is that you shouldn't be penalised if you right them retrospectively rather than first. If you're not comfortable doing TDD in your day job, don't suddenly make out it's your bread and butter. Try and work how you would on your own. Don't fake it.</p>

<p>Another motivation for the pairing exercise is to see if, as a prospective pair, you can get on. If you relax and let your personality come through, you'll both have a better idea what it would be like pairing day in, day out.</p>

<h2>Hang ups</h2>

<p>Don't get hung up on the IDE, the API or even the problem. The interviewer shouldn't be judging you based on what shortcuts your know or what API you know off by heart. If they do, then you should question what's important to them; an adaptive, bright, enthusiastic developer or a robot that knows emacs keyboard bindings?</p>

<p>With regards to the problem; if its not obvious, ask. A well set pairing exercise should be simple enough to quickly understand what's required and get you coding. Bogging you down with the complexities of the problem doesn't help anyone. Really. Don't be afraid to ask, it's what we do in our day jobs right?</p>

<h2>Nerves</h2>

<p>The thing that always gets me is nerves. I put way too much pressure on myself with an involuntary, internal commentary saying "am I doing enough? is that what they want to see? do they want to see this fancy thing? or that fancy thing?". Don't be like me, give yourself a break. You're a professional and good at what you do, you don't need to show off.</p>

<p>I guess this all leads to my final point...</p>

<h2>Summary</h2>

<p>Discuss the problem. Discuss what you're thinking. Discuss what you plan to do. Discuss. Discuss. Discuss.</p>

<p>If you get the chance, even mention some of the awesome things you've done. It's a great opportunity to talk to the devs you could actually be working with. So ask them about the project, about what floats <em>their</em> boat. Remember that you're interviewing them as much as the other way round.</p>

<p>Communication is key in what we do and it's key in any pairing exercises. If you're open, honest and communicative, you won't go far wrong in a well conducted pairing exercise. Don't forget too that conducting a pairing exercise is difficult and takes practice. So don't be too disheartened if it doesn't go well, but <a href="/blog/2011/08/29/reflecting-on-interviewing-mistakes">reflect and learn from it</a>.</p>

<p>Good luck!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hexagonal Acceptance Testing]]></title>
    <link href="http://baddotrobot.com/blog/2012/02/13/hexagonal-acceptance-testing/"/>
    <updated>2012-02-13T21:24:00+00:00</updated>
    <id>http://baddotrobot.com/blog/2012/02/13/hexagonal-acceptance-testing</id>
    <content type="html"><![CDATA[<p>There's no reason a unit test can't also be an acceptance test. If you can prove that the <em>unit</em> behaves a certain way <em>and</em> that in production, it will behave in the same way as in your unit test, the intersection should give you enough confidence.</p>

<p>What seems to make things harder to discuss is that its difficult to agree on a common definition for the different types of testing. As a peer-group, we're usually horrified by the previous paragraph and ask the question <em>"shouldn't we start up the entire stack in an acceptance test?"</em>. This often leads us to long-running, duplicative and expensive tests in the name of acceptance testing.</p>

<p>Taking inspiration from Cockburn's <a href="http://alistair.cockburn.us/Hexagonal+architecture">Hexagonal Architecture</a> and being more flexible in our technical definitions of acceptance testing however, we <em>can</em> create lightning fast acceptance testing.</p>

<!-- more -->  


<h2>Conway's Law</h2>

<p>To paraphrase something <a href="https://twitter.com/#!/Jazzatola">@Jazzatola</a> recently said</p>

<p><blockquote><p>"people are usually happy to test interactions with other systems 'by specification' but are less happy to do so when testing their internal systems"</p><footer><strong>@Jazzatola</strong> <cite><a href='https://twitter.com/#!/Jazzatola'>twitter.com/#!/Jazzatola/&hellip;</a></cite></footer></blockquote></p>

<p>As he points out; we're happy to say "given the external system responds with <code>X</code>, when we send a message <code>Y</code> then our system behaves <code>Z</code>". We know the API and test against it as a <em>specification</em>, typically via <em>mocking</em> the behaviour of the external system and testing against the response. We're less happy to talk about our internal interactions as internal APIs in the same way.</p>

<p>I find this interesting for a couple of reasons. <a href="https://twitter.com/#!/Jazzatola">@Jazzatola</a> was suggesting that this is an example of <a href="http://en.wikipedia.org/wiki/Conway's_law">Conway's law</a>; where the communication structures within an organisation are leading design. We're physically separated from our external system actors but intimately acquainted with the internal communication flows. After all, we wrote them.</p>

<p>It's also interesting because it can limit how we go about implementing our acceptance tests.</p>

<h2>Hexagonal Implementation</h2>

<p>If we look at our system as a series of <em>ports</em> and <em>adaptors</em> (as in Cockburn's <a href="http://alistair.cockburn.us/Hexagonal+architecture">Hexagonal Architecture</a>), we can start to test it as a series of internal, co-operating handoffs. Don't we already test our systems like this; with conventional mocking? The difference is that this kind of mocking is at a finer grained level; we mock <em>collaborators</em> to create unit-style tests and drive out design. When we mock external systems and the <em>ports</em> in our internal systems, we're mocking coarse grained <em>behaviours</em>. We're confirming an established design rather than driving one out. We can formalise this established design as <em>ports</em>.</p>

<p>If you look closely at the last few sentences you'll notice that I'm talking about <em>test confirm</em> at the coarse grained level rather than the <em>test driving</em> techniques we apply with unit-style tests. I think this is natural fit for acceptance testing where we should be thinking about testing the external affects produced by internal flows (more black than white box).</p>

<p>So, given we expect an internal interaction to behave in such-and-such way, why do we need to startup the entire application to exercise the effect of that behaviour? We don't. We can <em>simulate</em> the specification internally by mocking and produce a series of overlapping tests. Each one supporting and giving more confidence to the last.</p>

<p>We've certainly had some great successes with this technique. We've produced faster running test suites that customers were happy to "accept" or sign-off against. We built trust working with the customers to understand the approach and put ourselves more easily in their 'voice' describing the system as a series of internal API interactions.</p>

<h3>Conventional Hexagonal Architecture Footnote</h3>

<p>In the original article, Cockburn talks about ports and adaptors as a fairly abstract architectural approach. He describes it in terms of a pattern which have slightly different motivations than those described here.</p>

<p>He talks about a relatively small number of <em>ports</em> (say ~4-5) and decoupling <em>major</em> components of a system (for example, the database and the GUI) so that it can be driven and tested by different <em>external</em> actors.</p>

<p>I'm talking more about changing the <em>external</em> nature of these actors to be more <em>internal</em>. If we have a much larger number of ports (say >30), decoupling <em>minor</em> components we can achieve this substitutabiliy on a bigger scale and be more flexible on how we test the system.</p>

<p>Cockburn described an approach where we can test the system at end-to-end via it's ports. Taking this further to confirm small business functionality or <em>acceptance criteria</em> is a logical progression and fits nicely into iterative development.</p>

<p>Have a go and see if it works for you...</p>

<p>Liquid error: 765: unexpected token at ''</p>
]]></content>
  </entry>
  
</feed>
